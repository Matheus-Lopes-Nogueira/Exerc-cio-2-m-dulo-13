{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Scores para Ridge:\n",
      "Alpha 0: R² = 0.3470\n",
      "Alpha 0.001: R² = 0.3484\n",
      "Alpha 0.005: R² = 0.3484\n",
      "Alpha 0.01: R² = 0.3484\n",
      "Alpha 0.05: R² = 0.3484\n",
      "Alpha 0.1: R² = 0.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lopes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\Lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Lopes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+03, tolerance: 8.797e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Scores para LASSO:\n",
      "Alpha 0: R² = 0.3484\n",
      "Alpha 0.001: R² = 0.3487\n",
      "Alpha 0.005: R² = 0.3470\n",
      "Alpha 0.01: R² = 0.3434\n",
      "Alpha 0.05: R² = 0.3111\n",
      "Alpha 0.1: R² = 0.2485\n",
      "R² para Stepwise: 0.3479\n",
      "R² para Árvore de Regressão: 0.3016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente'], inplace=True)\n",
    "df['tempo_emprego'] = df['tempo_emprego'].fillna(df['tempo_emprego'].mean())\n",
    "\n",
    "X = df.drop(columns=['renda'])\n",
    "y = np.log(df['renda'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "num_features = ['idade', 'tempo_emprego', 'qt_pessoas_residencia', 'qtd_filhos']\n",
    "cat_features = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "ridge_results = {}\n",
    "for alpha in alphas:\n",
    "    ridge = make_pipeline(preprocessor, Ridge(alpha=alpha))\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    ridge_results[alpha] = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R2 Scores para Ridge:\")\n",
    "for alpha, r2 in ridge_results.items():\n",
    "    print(f\"Alpha {alpha}: R² = {r2:.4f}\")\n",
    "\n",
    "lasso_results = {}\n",
    "for alpha in alphas:\n",
    "    lasso = make_pipeline(preprocessor, Lasso(alpha=alpha))\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    lasso_results[alpha] = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R2 Scores para LASSO:\")\n",
    "for alpha, r2 in lasso_results.items():\n",
    "    print(f\"Alpha {alpha}: R² = {r2:.4f}\")\n",
    "\n",
    "stepwise_model = Ridge(alpha=0.01)\n",
    "sfs = SequentialFeatureSelector(stepwise_model, n_features_to_select='auto', direction='forward')\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "sfs.fit(X_train_transformed, y_train)\n",
    "\n",
    "selected_features = sfs.get_support()\n",
    "X_train_selected = X_train_transformed[:, selected_features]\n",
    "X_test_selected = X_test_transformed[:, selected_features]\n",
    "\n",
    "stepwise_model.fit(X_train_selected, y_train)\n",
    "y_pred = stepwise_model.predict(X_test_selected)\n",
    "stepwise_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² para Stepwise: {stepwise_r2:.4f}\")\n",
    "\n",
    "decision_tree = make_pipeline(preprocessor, DecisionTreeRegressor(random_state=42))\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "dt_r2 = r2_score(y_test, y_pred_tree)\n",
    "print(f\"R² para Árvore de Regressão: {dt_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
